{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch 1.3.1\n",
    "### cuda 10.1\n",
    "### Dataset = Sleep-edf-2013\n",
    "### pip install pyEDFlib : python에서 edf 파일을 열기 위한 라이브러리\n",
    "### pip install matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyedflib import highlevel\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 search_annotations_edf \n",
    "#### 해당 함수는 Hypnogram.edf이라는 이름을 가진 파일만 추려내기 위한 함수이며 해당 파일들은 annotations ( sleep stage ) 정보를 저장하고 있는 파일이다.\n",
    "\n",
    "### 함수 search_signals_edf \n",
    "#### 해당 함수는 PSG.edf이라는 이름을 가진 파일만 추려내기 위한 함수이며 해당 파일들은 signals 정보를 저장하고 있는 파일이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_annotations_edf(dirname):\n",
    "    filenames = os.listdir(dirname)\n",
    "    filenames = [file for file in filenames if file.endswith(\"Hypnogram.edf\")]\n",
    "    return filenames\n",
    "\n",
    "def search_signals_edf(dirname):\n",
    "    filenames = os.listdir(dirname)\n",
    "    filenames = [file for file in filenames if file.endswith(\"PSG.edf\")]\n",
    "    return filenames\n",
    "\n",
    "def search_correct_annotations(dirname,filename):\n",
    "    search_filename = filename.split('-')[0][:-2]\n",
    "    file_list = os.listdir(dirname)\n",
    "    filename = [file for file in file_list if search_filename in file if file.endswith(\"Hypnogram.edf\")]\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def search_signals_npy(dirname):\n",
    "    filenames = os.listdir(dirname)\n",
    "    filenames = [file for file in filenames if file.endswith(\".npy\")]\n",
    "    return filenames\n",
    "\n",
    "def search_correct_annotations_npy(dirname,filename):\n",
    "    search_filename = filename.split('-')[0][:-2]\n",
    "    file_list = os.listdir(dirname)\n",
    "    filename = [file for file in file_list if search_filename in file if file.endswith(\"npy\")]\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def search_correct_signals_npy(dirname,filename):\n",
    "    search_filename = filename.split('-')[0][:-2]\n",
    "    file_list = os.listdir(dirname)\n",
    "    filename = [file for file in file_list if search_filename in file if file.endswith(\"npy\")]\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/dataset/data_2013/' # sleep-edf 2013 데이터를 가지고 있는 폴더 명\n",
    "annotations_edf_list = search_annotations_edf(path)\n",
    "signals_edf_list = search_signals_edf(path)\n",
    "\n",
    "print('signals edf file list')\n",
    "print(signals_edf_list)\n",
    "\n",
    "print('annotations edf file list')\n",
    "print(annotations_edf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### signals_edf_list[0].split('-')[0][:-2]\n",
    "#### signals 와 같은 annotations 파일을 찾기 위함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in signals_edf_list:\n",
    "#     print('signals file name : %s , annotations file name : %s'%(filename,search_correct_annotations(signal_path,filename)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 30\n",
    "sample_rate = 100\n",
    "save_signals_path = path + 'origin_npy/'\n",
    "save_annotations_path = save_signals_path+'annotations/'\n",
    "\n",
    "os.makedirs(save_annotations_path,exist_ok=True)\n",
    "os.makedirs(save_signals_path,exist_ok=True)\n",
    "\n",
    "for filename in signals_edf_list:\n",
    "    signals_filename = filename\n",
    "    annotations_filename = search_correct_annotations(signal_path,filename)[0]\n",
    "    \n",
    "    signals_filename = path + signals_filename\n",
    "    annotations_filename = path + annotations_filename\n",
    "    \n",
    "    _, _, annotations_header = highlevel.read_edf(annotations_filename)\n",
    "    \n",
    "    label = []\n",
    "    for ann in annotations_header['annotations']:\n",
    "        start = ann[0]\n",
    "\n",
    "        length = ann[1]\n",
    "        length = int(str(length)[2:-1]) // epoch_size # label은 30초 간격으로 사용할 것이기 때문에 30으로 나눈 값이 해당 sleep stage가 반복된 횟수이다.\n",
    "        \n",
    "        if ann[2] == 'Sleep stage W':\n",
    "            for time in range(length):\n",
    "                label.append(0)\n",
    "        elif ann[2] == 'Sleep stage 1':\n",
    "            for time in range(length):\n",
    "                label.append(1)\n",
    "        elif ann[2] == 'Sleep stage 2':\n",
    "            for time in range(length):\n",
    "                label.append(2)\n",
    "        elif ann[2] == 'Sleep stage 3':\n",
    "            for time in range(length):\n",
    "                label.append(3)\n",
    "        elif ann[2] == 'Sleep stage 4':\n",
    "            for time in range(length):\n",
    "                label.append(3)\n",
    "        elif ann[2] == 'Sleep stage R':\n",
    "            for time in range(length):\n",
    "                label.append(4)\n",
    "        else:\n",
    "            for time in range(length):\n",
    "                label.append(5)\n",
    "    label = np.array(label)\n",
    "    signals, _, signals_header = highlevel.read_edf(signals_filename)\n",
    "    \n",
    "    \n",
    "    signals_len = len(signals[0]) // sample_rate // epoch_size\n",
    "    annotations_len = len(label)\n",
    "    if signals_header['startdate'] == annotations_header['startdate']:\n",
    "        print(\"%s file's signal & annotations start time is same\"%signals_filename.split('/')[-1])\n",
    "        \n",
    "        if signals_len > annotations_len :\n",
    "            signals = signals[:3][:annotations_len]\n",
    "        elif signals_len < annotations_len :\n",
    "            signals = signals[:3]\n",
    "            label = label[:signals_len]\n",
    "        else:\n",
    "            signals = signals[:3]\n",
    "        signals = np.array(signals)\n",
    "        \n",
    "        np.save(save_signals_path + signals_filename.split('/')[-1].split('.')[0],signals)\n",
    "        np.save(save_annotations_path + annotations_filename.split('/')[-1].split('.')[0],label)\n",
    "        \n",
    "        if (len(signals[0])//sample_rate//epoch_size != len(label)):\n",
    "            print('signals len : %d / annotations len : %d'%(len(signals[0])//sample_rate//epoch_size,len(label)))\n",
    "        \n",
    "    else:\n",
    "        print(\"%s file''s signal & annotations start time is different\"%signals_filename.split('/')[-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signals\n",
    "#### channel 0 : EEG Fpz-Cz , sample rate = 100 , dimension = $\\mu$V prefilter : HP = 0.5Hz , LP = 100Hz\n",
    "#### channel 1 : EEG Pz-Oz , sample rate = 100 , dimension = $\\mu$V prefilter : HP = 0.5Hz , LP = 100Hz\n",
    "#### channel 2 : EOG horizontal , sample rate = 100 , dimension = $\\mu$V prefilter : HP = 0.5Hz , LP = 100Hz\n",
    "#### channel 3 : Resp oro-nasal \n",
    "#### channel 4 : EMG submental\n",
    "#### channel 5 : Temp rectal\n",
    "#### channel 6 : Event marker\n",
    "\n",
    "#### 실제로 학습에 사용하는 채널은 0,1 채널이고, Benchmark에서 높은 성능을 가지는 채널은 0번 채널 ( Fpz-Cz )이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 30\n",
    "sample_rate = 100\n",
    "\n",
    "path =  'D:/dataset/data_2013/origin_npy/'\n",
    "\n",
    "signals_npy_list = search_signals_npy(path)\n",
    "\n",
    "print(signals_npy_list)\n",
    "\n",
    "channel_name_list = ['Fpz-Cz/','Pz-Oz/','EOG/']\n",
    "for channel_index,channel_name in enumerate(channel_name_list):\n",
    "    save_path = path + channel_name\n",
    "    os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "    for filename in signals_npy_list:\n",
    "        signals_filename = filename\n",
    "\n",
    "        signals_filename = path + signals_filename\n",
    "        \n",
    "        signals = np.load(signals_filename)\n",
    "        \n",
    "        signals = signals[channel_index].reshape(1,-1)\n",
    "        print(signals.shape)\n",
    "        \n",
    "        np.save(save_path + filename,signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel 별 npy 파일 분리 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 30\n",
    "sample_rate = 100\n",
    "\n",
    "path =  'D:/dataset/data_2013/origin_npy/Fpz-Cz/'\n",
    "annotations_path = 'D:/dataset/data_2013/origin_npy/annotations/'\n",
    "signals_npy_list = search_signals_npy(path)\n",
    "\n",
    "print(signals_npy_list)\n",
    "\n",
    "\n",
    "for filename in signals_npy_list:\n",
    "    signals_filename = path + filename\n",
    "    annotations_filename = annotations_path+search_correct_annotations_npy(annotations_path,filename)[0]\n",
    "    signals = np.load(signals_filename)\n",
    "    label = np.load(annotations_filename)\n",
    "    if len(signals[0])//sample_rate//epoch_size != len(label):\n",
    "        print('%s is fault'%filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 100                                # Sampling rate (512 Hz)\n",
    "epoch_size = 30\n",
    "#data = np.random.uniform(0, 100, 1024)  # 2 sec of data b/w 0.0-100.0\n",
    "\n",
    "path =  'D:/dataset/data_2013/origin_npy/Fpz-Cz/'\n",
    "\n",
    "signals_npy_list = search_signals_npy(path)\n",
    "\n",
    "for filename in signals_npy_list:\n",
    "    signals = np.load(path+filename)\n",
    "    length = len(signals[0])//fs//epoch_size\n",
    "    print(signals.shape)\n",
    "    for index in range(length):\n",
    "        data = signals[0,int(index*fs*30) : int((index+1)*fs*30)]\n",
    "        # Get real amplitudes of FFT (only in postive frequencies)\n",
    "        fft_vals = np.absolute(np.fft.rfft(data)) / (fs*epoch_size)# real fft 계산 \n",
    "\n",
    "        \n",
    "        #         fft_vals[:1*30+1] = 0\n",
    "        #         fft_vals[35*30:] = 0\n",
    "        \n",
    "        # Get frequencies for amplitudes in Hz\n",
    "        fft_freq = np.fft.rfftfreq(len(data), 1.0/fs)\n",
    "\n",
    "        # Define EEG bands\n",
    "        eeg_bands = {'Delta-0-0.5': (0, 0.5),\n",
    "                     'Delta-0.5-1': (0.5, 1),\n",
    "                     'Delta-1-2': (1, 2),\n",
    "                     'Delta-2-3': (2, 3),\n",
    "                     'Delta-3-4': (3, 4),\n",
    "                     'Theta-4-5': (4, 5),\n",
    "                     'Theta-5-6': (5, 6),\n",
    "                     'Theta-6-7': (6, 7),\n",
    "                     'Theta-7-8': (7, 8),\n",
    "                     'Alpha-8-9': (8, 9),\n",
    "                     'Alpha-9-10': (9, 10),\n",
    "                     'Alpha-10-11': (10, 11),\n",
    "                     'Alpha-11-12': (11, 12),\n",
    "                     'Beta': (12, 30),\n",
    "                     'Gamma': (30, 45)}\n",
    "\n",
    "        # Take the mean of the fft amplitude for each EEG band\n",
    "        eeg_band_fft = []\n",
    "        for band in eeg_bands:  \n",
    "            #print('band : ',band)\n",
    "            freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & \n",
    "                               (fft_freq <= eeg_bands[band][1]))[0]\n",
    "            \n",
    "            eeg_band_fft.append(np.mean(fft_vals[freq_ix]))\n",
    "        eeg_band_fft = np.array(eeg_band_fft)\n",
    "        # Plot the data (using pandas here cause it's easy)\n",
    "\n",
    "        print(eeg_bands.keys())\n",
    "        print(eeg_band_fft)\n",
    "        plt.bar(eeg_bands.keys(),eeg_band_fft)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency 대역 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 100                                # Sampling rate (512 Hz)\n",
    "epoch_size = 30\n",
    "#data = np.random.uniform(0, 100, 1024)  # 2 sec of data b/w 0.0-100.0\n",
    "\n",
    "path =  'D:/dataset/data_2013/origin_npy/annotations/'\n",
    "\n",
    "annotations_npy_list = search_signals_npy(path)\n",
    "\n",
    "check_index_size = 10\n",
    "\n",
    "for filename in annotations_npy_list:\n",
    "    label_info = np.zeros([5],dtype=int)\n",
    "    label = np.load(path + filename)\n",
    "    \n",
    "    \n",
    "\n",
    "    plt.plot(label)\n",
    "    plt.show()\n",
    "    print('='*20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 100                                # Sampling rate (512 Hz)\n",
    "epoch_size = 30\n",
    "#data = np.random.uniform(0, 100, 1024)  # 2 sec of data b/w 0.0-100.0\n",
    "\n",
    "path =  'D:/dataset/data_2013/origin_npy/annotations/'\n",
    "signals_path = 'D:/dataset/data_2013/origin_npy/Fpz-Cz/'\n",
    "\n",
    "save_annotations_path = path + 'remove_wake/'\n",
    "save_signals_path = signals_path + 'remove_wake/'\n",
    "\n",
    "os.makedirs(save_annotations_path,exist_ok=True)\n",
    "os.makedirs(save_signals_path,exist_ok=True)\n",
    "annotations_npy_list = search_signals_npy(path)\n",
    "\n",
    "check_index_size = 10\n",
    "\n",
    "total_label = np.zeros([6],dtype=int)\n",
    "\n",
    "for filename in annotations_npy_list:\n",
    "    label = np.load(path + filename)\n",
    "    signals_filename = search_correct_signals_npy(signals_path,filename)[0]\n",
    "    \n",
    "    signals = np.load(signals_path+signals_filename)\n",
    "    \n",
    "    for remove_start_index in range(0,len(label),1):\n",
    "        #print(np.bincount(label[remove_start_index:(remove_start_index+check_index_size)],minlength=6)[0])\n",
    "        if(np.bincount(label[remove_start_index:(remove_start_index+check_index_size)],minlength=6)[0] != check_index_size):\n",
    "            break\n",
    "            \n",
    "    for remove_end_index in range(len(label),-1,-1,):\n",
    "        #print(np.bincount(label[remove_end_index-check_index_size:(remove_end_index)],minlength=6)[0])\n",
    "        if(np.bincount(label[remove_end_index-check_index_size:(remove_end_index)],minlength=6)[0] != check_index_size and np.bincount(label[remove_end_index-check_index_size:(remove_end_index)],minlength=6)[5] == 0 ):\n",
    "            break\n",
    "    \n",
    "    #print('remove start index : %d / remove end index : %d'%(remove_start_index,remove_end_index))\n",
    "    label = label[remove_start_index:remove_end_index+1]\n",
    "    signals = signals[0,remove_start_index*fs*epoch_size:(remove_end_index+1)*fs*epoch_size].reshape(1,-1)\n",
    "    #print(np.bincount(label,minlength=6))\n",
    "    if len(label) ==len(signals[0])//30//fs:\n",
    "        np.save(save_annotations_path+filename.split('.')[0],label)\n",
    "        np.save(save_signals_path+signals_filename.split('.')[0],signals)\n",
    "    for i in range(6):\n",
    "        total_label[i] += np.bincount(label,minlength=6)[i]\n",
    "    \n",
    "    \n",
    "print(total_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wake 수 줄이는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4258  2762 17340  5575  7522    59]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 6 artists>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASgklEQVR4nO3df6zddX3H8edrRZxTCTgurGth7Uw1QbJVuUESonFDsICxuOjWZpPOsVUNZDOabGX7A6cjYZvOjcRhqjaWzNGxIaORKnbMjZiA9FYrP0TWC3ZybUMrdRPjgim+98f53O3YntvennN6z237fCQn5/t9fz/f731/Q+jrfj/f7zk3VYUk6eT2U6NuQJI0eoaBJMkwkCQZBpIkDANJEnDKqBvo15lnnllLliwZdRuSdFzZvn37d6tq7OD6cRsGS5YsYWJiYtRtSNJxJcl/9qo7TSRJMgwkSYaBJAnDQJLELMIgyYYke5M80lX7hyQ72mtXkh2tviTJ/3Rt+3jXPhckeTjJZJKbk6TVX5Zka5Kd7f2MY3GikqSZzebK4NPAiu5CVf1GVS2vquXAHcBnuzY/Mb2tqt7dVb8FWAssa6/pY64D7q2qZcC9bV2SNIeOGAZVdR+wv9e29tv9rwO3He4YSRYCp1XV/dX5mtRbgava5pXAxra8sasuSZojg94zeB3wdFXt7KotTfK1JP+e5HWttgiY6hoz1WoAZ1fVHoD2ftZMPyzJ2iQTSSb27ds3YOuSpGmDhsFqfvKqYA9wblW9Gngf8PdJTgPSY9+j/kMKVbW+qsaranxs7JAP0EmS+tT3J5CTnAL8GnDBdK2qngOea8vbkzwBvILOlcDirt0XA7vb8tNJFlbVnjadtLffnnTiWbLu7lG3cIhdN1056hakoRvkyuCNwDer6v+mf5KMJVnQln+Rzo3iJ9v0z7NJLmr3Ga4G7mq7bQbWtOU1XXVJ0hyZzaOltwH3A69MMpXkmrZpFYfeOH498FCSrwP/BLy7qqZvPr8H+CQwCTwBfL7VbwIuTbITuLStS5Lm0BGniapq9Qz13+5Ru4POo6a9xk8A5/eoPwNccqQ+JEnHjp9AliQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJDGLMEiyIcneJI901T6Q5DtJdrTXFV3brk8ymeTxJG/qqq9otckk67rqS5N8JcnOJP+Q5NRhnqAk6chmc2XwaWBFj/pHq2p5e20BSHIesAp4Vdvnb5MsSLIA+BhwOXAesLqNBfjzdqxlwPeAawY5IUnS0TtiGFTVfcD+WR5vJbCpqp6rqm8Bk8CF7TVZVU9W1Y+ATcDKJAF+Ffintv9G4KqjPAdJ0oAGuWdwXZKH2jTSGa22CHiqa8xUq81U/1ngv6rqwEH1npKsTTKRZGLfvn0DtC5J6tZvGNwCvBxYDuwBPtLq6TG2+qj3VFXrq2q8qsbHxsaOrmNJ0oxO6Wenqnp6ejnJJ4DPtdUp4JyuoYuB3W25V/27wOlJTmlXB93jJUlzpK8rgyQLu1bfCkw/abQZWJXkhUmWAsuAB4FtwLL25NCpdG4yb66qAr4EvK3tvwa4q5+eJEn9O+KVQZLbgDcAZyaZAm4A3pBkOZ0pnV3AuwCq6tEktwPfAA4A11bV8+041wH3AAuADVX1aPsRfwRsSvJnwNeATw3t7CRJs3LEMKiq1T3KM/6DXVU3Ajf2qG8BtvSoP0nnaSNJ0oj4CWRJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiRmEQZJNiTZm+SRrtpfJvlmkoeS3Jnk9FZfkuR/kuxor4937XNBkoeTTCa5OUla/WVJtibZ2d7POBYnKkma2WyuDD4NrDiothU4v6p+CfgP4PqubU9U1fL2endX/RZgLbCsvaaPuQ64t6qWAfe2dUnSHDpiGFTVfcD+g2pfrKoDbfUBYPHhjpFkIXBaVd1fVQXcClzVNq8ENrbljV11SdIcGcY9g98BPt+1vjTJ15L8e5LXtdoiYKprzFSrAZxdVXsA2vtZQ+hJknQUThlk5yR/AhwAPtNKe4Bzq+qZJBcA/5zkVUB67F59/Ly1dKaaOPfcc/trWpJ0iL6vDJKsAd4M/Gab+qGqnquqZ9ryduAJ4BV0rgS6p5IWA7vb8tNtGml6OmnvTD+zqtZX1XhVjY+NjfXbuiTpIH2FQZIVwB8Bb6mqH3bVx5IsaMu/SOdG8ZNt+ufZJBe1p4iuBu5qu20G1rTlNV11SdIcOeI0UZLbgDcAZyaZAm6g8/TQC4Gt7QnRB9qTQ68HPpjkAPA88O6qmr75/B46Tya9iM49hun7DDcBtye5Bvg28PahnJkkadaOGAZVtbpH+VMzjL0DuGOGbRPA+T3qzwCXHKkPSdKx4yeQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkScwyDJJsSLI3ySNdtZcl2ZpkZ3s/o9WT5OYkk0keSvKarn3WtPE7k6zpql+Q5OG2z81JMsyTlCQd3myvDD4NrDiotg64t6qWAfe2dYDLgWXttRa4BTrhAdwAvBa4ELhhOkDamLVd+x38syRJx9CswqCq7gP2H1ReCWxsyxuBq7rqt1bHA8DpSRYCbwK2VtX+qvoesBVY0badVlX3V1UBt3YdS5I0Bwa5Z3B2Ve0BaO9ntfoi4KmucVOtdrj6VI/6IZKsTTKRZGLfvn0DtC5J6nYsbiD3mu+vPuqHFqvWV9V4VY2PjY0N0KIkqdsgYfB0m+Khve9t9SngnK5xi4HdR6gv7lGXJM2RQcJgMzD9RNAa4K6u+tXtqaKLgP9u00j3AJclOaPdOL4MuKdtezbJRe0poqu7jiVJmgOnzGZQktuANwBnJpmi81TQTcDtSa4Bvg28vQ3fAlwBTAI/BN4JUFX7k3wI2NbGfbCqpm9Kv4fOE0svAj7fXpKkOTKrMKiq1TNsuqTH2AKuneE4G4ANPeoTwPmz6UWSNHx+AlmSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJLEAGGQ5JVJdnS9vp/kvUk+kOQ7XfUruva5PslkkseTvKmrvqLVJpOsG/SkJElH55R+d6yqx4HlAEkWAN8B7gTeCXy0qj7cPT7JecAq4FXAzwP/kuQVbfPHgEuBKWBbks1V9Y1+e5MkHZ2+w+AglwBPVNV/JplpzEpgU1U9B3wrySRwYds2WVVPAiTZ1MYaBpI0R4YVBquA27rWr0tyNTABvL+qvgcsAh7oGjPVagBPHVR/ba8fkmQtsBbg3HPPHU7nkoZiybq7R93CIXbddOWoWzhuDHwDOcmpwFuAf2ylW4CX05lC2gN8ZHpoj93rMPVDi1Xrq2q8qsbHxsYG6luS9P+GcWVwOfDVqnoaYPodIMkngM+11SngnK79FgO72/JMdUnSHBjGo6Wr6ZoiSrKwa9tbgUfa8mZgVZIXJlkKLAMeBLYBy5IsbVcZq9pYSdIcGejKIMnP0HkK6F1d5b9IspzOVM+u6W1V9WiS2+ncGD4AXFtVz7fjXAfcAywANlTVo4P0JUk6OgOFQVX9EPjZg2rvOMz4G4Ebe9S3AFsG6UWS1D8/gSxJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQG/Etnko7eknV3j7qFnnbddOWoW9AIeWUgSTIMJEmGgSSJIYRBkl1JHk6yI8lEq70sydYkO9v7Ga2eJDcnmUzyUJLXdB1nTRu/M8maQfuSJM3esK4MfqWqllfVeFtfB9xbVcuAe9s6wOXAsvZaC9wCnfAAbgBeC1wI3DAdIJKkY+9YTROtBDa25Y3AVV31W6vjAeD0JAuBNwFbq2p/VX0P2AqsOEa9SZIOMowwKOCLSbYnWdtqZ1fVHoD2flarLwKe6tp3qtVmqv+EJGuTTCSZ2Ldv3xBalyTBcD5ncHFV7U5yFrA1yTcPMzY9anWY+k8WqtYD6wHGx8cP2S5J6s/AVwZVtbu97wXupDPn/3Sb/qG9723Dp4BzunZfDOw+TF2SNAcGCoMkL07y0ull4DLgEWAzMP1E0Brgrra8Gbi6PVV0EfDfbRrpHuCyJGe0G8eXtZokaQ4MOk10NnBnkulj/X1VfSHJNuD2JNcA3wbe3sZvAa4AJoEfAu8EqKr9ST4EbGvjPlhV+wfsTZI0SwOFQVU9Cfxyj/ozwCU96gVcO8OxNgAbBulHktQfP4EsSTIMJEmGgSSJk/TvGczH75P3u+QljZJXBpIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgSWKAv3SW5BzgVuDngB8D66vqb5J8APg9YF8b+sdVtaXtcz1wDfA88PtVdU+rrwD+BlgAfLKqbuq3r5PVfPzrbeBfcJOOF4P82csDwPur6qtJXgpsT7K1bftoVX24e3CS84BVwKuAnwf+Jckr2uaPAZcCU8C2JJur6hsD9CZJOgp9h0FV7QH2tOVnkzwGLDrMLiuBTVX1HPCtJJPAhW3bZFU9CZBkUxtrGEjSHBnKPYMkS4BXA19ppeuSPJRkQ5IzWm0R8FTXblOtNlO9189Zm2QiycS+fft6DZEk9WHgMEjyEuAO4L1V9X3gFuDlwHI6Vw4fmR7aY/c6TP3QYtX6qhqvqvGxsbFBW5ckNYPcMyDJC+gEwWeq6rMAVfV01/ZPAJ9rq1PAOV27LwZ2t+WZ6pKkOdD3lUGSAJ8CHquqv+qqL+wa9lbgkba8GViV5IVJlgLLgAeBbcCyJEuTnErnJvPmfvuSJB29Qa4MLgbeATycZEer/TGwOslyOlM9u4B3AVTVo0lup3Nj+ABwbVU9D5DkOuAeOo+WbqiqRwfoS5J0lAZ5mujL9J7v33KYfW4EbuxR33K4/SRJx5afQJYkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCQxj8IgyYokjyeZTLJu1P1I0slkXoRBkgXAx4DLgfOA1UnOG21XknTyOGXUDTQXApNV9SRAkk3ASuAbI+1K0kltybq7R93CIXbddOUxOW6q6pgc+KiaSN4GrKiq323r7wBeW1XXHTRuLbC2rb4SeHxOG+3tTOC7o25iyE7Ec4IT87w8p+PHfDmvX6iqsYOL8+XKID1qh6RUVa0H1h/7dmYvyURVjY+6j2E6Ec8JTszz8pyOH/P9vObFPQNgCjina30xsHtEvUjSSWe+hME2YFmSpUlOBVYBm0fckySdNObFNFFVHUhyHXAPsADYUFWPjrit2ZpX01ZDciKeE5yY5+U5HT/m9XnNixvIkqTRmi/TRJKkETIMJEmGQb9OxK/PSLIhyd4kj4y6l2FJck6SLyV5LMmjSf5g1D0NQ5KfTvJgkq+38/rTUfc0LEkWJPlaks+NupdhSLIrycNJdiSZGHU/M/GeQR/a12f8B3ApncditwGrq+q4/sR0ktcDPwBurarzR93PMCRZCCysqq8meSmwHbjqBPhvFeDFVfWDJC8Avgz8QVU9MOLWBpbkfcA4cFpVvXnU/QwqyS5gvKrmwwfOZuSVQX/+7+szqupHwPTXZxzXquo+YP+o+ximqtpTVV9ty88CjwGLRtvV4KrjB231Be113P9ml2QxcCXwyVH3crIxDPqzCHiqa32KE+AfmBNdkiXAq4GvjLaT4WjTKTuAvcDWqjoRzuuvgT8EfjzqRoaogC8m2d6+UmdeMgz6M6uvz9D8keQlwB3Ae6vq+6PuZxiq6vmqWk7nE/sXJjmup/aSvBnYW1XbR93LkF1cVa+h863M17bp2HnHMOiPX59xHGlz6ncAn6mqz466n2Grqv8C/g1YMeJWBnUx8JY2x74J+NUkfzfalgZXVbvb+17gTjrTzPOOYdAfvz7jONFutH4KeKyq/mrU/QxLkrEkp7flFwFvBL452q4GU1XXV9XiqlpC5/+pf62q3xpxWwNJ8uL24AJJXgxcBszLp/UMgz5U1QFg+uszHgNuP46+PmNGSW4D7gdemWQqyTWj7mkILgbeQee3zB3tdcWomxqChcCXkjxE55eTrVV1QjyKeYI5G/hykq8DDwJ3V9UXRtxTTz5aKknyykCSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJIE/C8nHoLX0zV5vgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fs = 100                                # Sampling rate (512 Hz)\n",
    "epoch_size = 30\n",
    "#data = np.random.uniform(0, 100, 1024)  # 2 sec of data b/w 0.0-100.0\n",
    "\n",
    "path =  'D:/dataset/data_2013/origin_npy/annotations/remove_wake/'\n",
    "signals_path = 'D:/dataset/data_2013/origin_npy/Fpz-Cz/remove_wake/'\n",
    "\n",
    "annotations_npy_list = search_signals_npy(path)\n",
    "\n",
    "total_label = np.zeros([6],dtype=int)\n",
    "\n",
    "for filename in annotations_npy_list:\n",
    "    label = np.load(path + filename)\n",
    "    signals_filename = search_correct_signals_npy(signals_path,filename)[0]\n",
    "    \n",
    "    signals = np.load(signals_path+signals_filename)\n",
    "    \n",
    "    \n",
    "    #print('remove start index : %d / remove end index : %d'%(remove_start_index,remove_end_index))\n",
    "    #print(np.bincount(label,minlength=6))\n",
    "    if len(label) !=len(signals[0])//30//fs:\n",
    "        print('file is fault!!!')\n",
    "    for i in range(6):\n",
    "        total_label[i] += np.bincount(label,minlength=6)[i]\n",
    "        \n",
    "print(total_label)\n",
    "\n",
    "x = np.arange(len(total_label))\n",
    "\n",
    "plt.bar(x,total_label,width=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(len(annotations_npy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 데이터셋 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SC4001EC-Hypnogram.npy', 'SC4002EC-Hypnogram.npy', 'SC4011EH-Hypnogram.npy', 'SC4012EC-Hypnogram.npy', 'SC4021EH-Hypnogram.npy', 'SC4022EJ-Hypnogram.npy', 'SC4031EC-Hypnogram.npy', 'SC4032EP-Hypnogram.npy', 'SC4041EC-Hypnogram.npy', 'SC4042EC-Hypnogram.npy', 'SC4051EC-Hypnogram.npy', 'SC4052EC-Hypnogram.npy', 'SC4061EC-Hypnogram.npy', 'SC4062EC-Hypnogram.npy', 'SC4071EC-Hypnogram.npy', 'SC4072EH-Hypnogram.npy', 'SC4081EC-Hypnogram.npy', 'SC4082EP-Hypnogram.npy', 'SC4091EC-Hypnogram.npy', 'SC4092EC-Hypnogram.npy', 'SC4101EC-Hypnogram.npy', 'SC4102EC-Hypnogram.npy', 'SC4111EC-Hypnogram.npy', 'SC4112EC-Hypnogram.npy', 'SC4121EC-Hypnogram.npy', 'SC4122EV-Hypnogram.npy', 'SC4131EC-Hypnogram.npy', 'SC4141EU-Hypnogram.npy', 'SC4142EU-Hypnogram.npy', 'SC4151EC-Hypnogram.npy', 'SC4152EC-Hypnogram.npy', 'SC4161EC-Hypnogram.npy', 'SC4171EU-Hypnogram.npy', 'SC4172EC-Hypnogram.npy', 'SC4181EC-Hypnogram.npy', 'SC4182EC-Hypnogram.npy', 'SC4191EP-Hypnogram.npy', 'SC4192EV-Hypnogram.npy']\n",
      "['SC4092EC-Hypnogram.npy', 'SC4171EU-Hypnogram.npy', 'SC4031EC-Hypnogram.npy', 'SC4072EH-Hypnogram.npy', 'SC4101EC-Hypnogram.npy', 'SC4022EJ-Hypnogram.npy', 'SC4161EC-Hypnogram.npy', 'SC4071EC-Hypnogram.npy', 'SC4102EC-Hypnogram.npy', 'SC4152EC-Hypnogram.npy', 'SC4061EC-Hypnogram.npy', 'SC4001EC-Hypnogram.npy', 'SC4111EC-Hypnogram.npy', 'SC4141EU-Hypnogram.npy', 'SC4131EC-Hypnogram.npy', 'SC4012EC-Hypnogram.npy', 'SC4122EV-Hypnogram.npy', 'SC4062EC-Hypnogram.npy', 'SC4192EV-Hypnogram.npy', 'SC4052EC-Hypnogram.npy', 'SC4042EC-Hypnogram.npy', 'SC4151EC-Hypnogram.npy', 'SC4021EH-Hypnogram.npy', 'SC4002EC-Hypnogram.npy', 'SC4181EC-Hypnogram.npy', 'SC4121EC-Hypnogram.npy', 'SC4081EC-Hypnogram.npy', 'SC4191EP-Hypnogram.npy', 'SC4011EH-Hypnogram.npy', 'SC4051EC-Hypnogram.npy', 'SC4142EU-Hypnogram.npy', 'SC4041EC-Hypnogram.npy', 'SC4112EC-Hypnogram.npy', 'SC4172EC-Hypnogram.npy', 'SC4182EC-Hypnogram.npy', 'SC4082EP-Hypnogram.npy', 'SC4091EC-Hypnogram.npy', 'SC4032EP-Hypnogram.npy']\n",
      "[11.15174913  7.62978767 46.29686071 14.49083951 20.28514342  0.14561956]\n",
      "[12.08213347  6.37285589 45.93714787 16.22636785 19.1811694   0.20032553]\n"
     ]
    }
   ],
   "source": [
    "fs = 100                                # Sampling rate (512 Hz)\n",
    "epoch_size = 30\n",
    "#data = np.random.uniform(0, 100, 1024)  # 2 sec of data b/w 0.0-100.0\n",
    "\n",
    "path =  'D:/dataset/data_2013/origin_npy/annotations/remove_wake/'\n",
    "signals_path = 'D:/dataset/data_2013/origin_npy/Fpz-Cz/remove_wake/'\n",
    "\n",
    "annotations_npy_list = search_signals_npy(path)\n",
    "\n",
    "print(annotations_npy_list)\n",
    "\n",
    "random.shuffle(annotations_npy_list)\n",
    "\n",
    "print(annotations_npy_list)\n",
    "\n",
    "trainDataset_count = 30\n",
    "testDataset_count = len(annotations_npy_list)-trainDataset_count\n",
    "\n",
    "train_label = np.zeros([6],dtype=int)\n",
    "test_label = np.zeros([6],dtype=int)\n",
    "\n",
    "for filename in annotations_npy_list[:trainDataset_count]:\n",
    "    label = np.load(path + filename)\n",
    "    \n",
    "    for i in range(6):\n",
    "        train_label[i] += np.bincount(label,minlength=6)[i]\n",
    "\n",
    "        \n",
    "for filename in annotations_npy_list[trainDataset_count:]:\n",
    "    label = np.load(path + filename)\n",
    "    \n",
    "    for i in range(6):\n",
    "        test_label[i] += np.bincount(label,minlength=6)[i]\n",
    "        \n",
    "train_label = train_label / np.sum(train_label) * 100\n",
    "test_label = test_label / np.sum(test_label) * 100\n",
    "print(train_label)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  'D:/dataset/data_2013/origin_npy/annotations/remove_wake/'\n",
    "signals_path = 'D:/dataset/data_2013/origin_npy/Fpz-Cz/remove_wake/'\n",
    "\n",
    "save_train_path = 'D:/dataset/data_2013/origin_npy/Fpz-Cz/remove_wake/train/'\n",
    "save_test_path = 'D:/dataset/data_2013/origin_npy/Fpz-Cz/remove_wake/test/'\n",
    "\n",
    "os.makedirs(save_train_path,exist_ok=True)\n",
    "os.makedirs(save_test_path,exist_ok=True)\n",
    "\n",
    "for filename in annotations_npy_list[:trainDataset_count]:\n",
    "    signals_filename = search_correct_signals_npy(signals_path,filename)[0]\n",
    "    shutil.copy(signals_path+signals_filename,save_train_path+filename)\n",
    "    \n",
    "\n",
    "        \n",
    "for filename in annotations_npy_list[trainDataset_count:]:\n",
    "    signals_filename = search_correct_signals_npy(signals_path,filename)[0]\n",
    "    shutil.copy(signals_path+signals_filename,save_test_path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SC4001EC-Hypnogram.npy', 'SC4011EH-Hypnogram.npy', 'SC4012EC-Hypnogram.npy', 'SC4021EH-Hypnogram.npy', 'SC4032EP-Hypnogram.npy', 'SC4041EC-Hypnogram.npy', 'SC4051EC-Hypnogram.npy', 'SC4052EC-Hypnogram.npy', 'SC4061EC-Hypnogram.npy', 'SC4062EC-Hypnogram.npy', 'SC4071EC-Hypnogram.npy', 'SC4081EC-Hypnogram.npy', 'SC4082EP-Hypnogram.npy', 'SC4091EC-Hypnogram.npy', 'SC4092EC-Hypnogram.npy', 'SC4102EC-Hypnogram.npy', 'SC4111EC-Hypnogram.npy', 'SC4112EC-Hypnogram.npy', 'SC4121EC-Hypnogram.npy', 'SC4122EV-Hypnogram.npy', 'SC4131EC-Hypnogram.npy', 'SC4142EU-Hypnogram.npy', 'SC4152EC-Hypnogram.npy', 'SC4161EC-Hypnogram.npy', 'SC4171EU-Hypnogram.npy', 'SC4172EC-Hypnogram.npy', 'SC4181EC-Hypnogram.npy', 'SC4191EP-Hypnogram.npy']\n",
      "['SC4002EC-Hypnogram.npy', 'SC4022EJ-Hypnogram.npy', 'SC4031EC-Hypnogram.npy', 'SC4042EC-Hypnogram.npy', 'SC4072EH-Hypnogram.npy', 'SC4101EC-Hypnogram.npy', 'SC4141EU-Hypnogram.npy', 'SC4151EC-Hypnogram.npy', 'SC4182EC-Hypnogram.npy', 'SC4192EV-Hypnogram.npy']\n",
      "[11.52193537  6.78461816 47.01570681 15.07853403 19.44394295  0.15526268]\n",
      "[10.86447409  8.99093779 43.97719173 14.24498524 21.75949496  0.1629162 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_path =  'D:/dataset/data_2013/origin_npy/Fpz-Cz/remove_wake/train/'\n",
    "test_path = 'D:/dataset/data_2013/origin_npy/Fpz-Cz/remove_wake/test/'\n",
    "annotations_path = 'D:/dataset/data_2013/origin_npy/annotations/remove_wake/'\n",
    "\n",
    "train_list = search_signals_npy(train_path)\n",
    "test_list = search_signals_npy(test_path)\n",
    "\n",
    "print(train_list)\n",
    "print(test_list)\n",
    "\n",
    "train_label = np.zeros([6],dtype=int)\n",
    "test_label = np.zeros([6],dtype=int)\n",
    "\n",
    "for filename in train_list:\n",
    "    filename = search_correct_annotations_npy(annotations_path,filename)[0]\n",
    "    label = np.load(annotations_path + filename)\n",
    "    \n",
    "    for i in range(6):\n",
    "        train_label[i] += np.bincount(label,minlength=6)[i]\n",
    "\n",
    "        \n",
    "for filename in test_list:\n",
    "    filename = search_correct_annotations_npy(annotations_path,filename)[0]\n",
    "    label = np.load(annotations_path + filename)\n",
    "    \n",
    "    for i in range(6):\n",
    "        test_label[i] += np.bincount(label,minlength=6)[i]\n",
    "        \n",
    "train_label = train_label / np.sum(train_label) * 100\n",
    "test_label = test_label / np.sum(test_label) * 100\n",
    "print(train_label)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.3.1-cuda10.1",
   "language": "python",
   "name": "pytorch-cuda10.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
